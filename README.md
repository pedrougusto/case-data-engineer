# Case API Fake Store | Enjoei/Elo7
Este reposit√≥rio cont√©m uma solu√ß√£o para o case de Engenharia de Dados J√∫nior da Enjoei/Elo7, que consiste em consumir dados de uma API, processar e transformar as informa√ß√µes e gerar uma sa√≠da em formato JSON. O foco principal √© coletar informa√ß√µes relevantes de usu√°rios e carrinhos de compras, incluindo a data mais recente de adi√ß√£o ao carrinho e a categoria com maior n√∫mero de produtos adicionados.

### T√≥picos: 
:small_blue_diamond: [Descri√ß√£o do Projeto](#descri√ß√£o-do-projeto)

:small_blue_diamond: [Tecnologias Utilizadas](#tecnologias-utilizadas)

:small_blue_diamond: [Estrutura do C√≥digo](#estrutura-do-c√≥digo)

:small_blue_diamond: [Funcionalidades](#funcionalidades)

:small_blue_diamond: [Sa√≠da do arquivo JSON](#sa√≠da-do-arquivo-json)

:small_blue_diamond: [An√°lise de Efici√™ncia](#an√°lise-de-efici√™ncia)

:small_blue_diamond: [Agradecimentos](#agradecimentos)

## üéØDescri√ß√£o do Projeto
Esse projeto √© uma solu√ß√£o para o case de engenharia de dados, onde foi necess√°rio:
- Consumir dados de dois endpoints diferentes da API Fake Store.
- Transformar e manipular os dados para extrair informa√ß√µes sobre cada usu√°rio e seus consumos.
- Persistir os dados em um arquivo JSON.

## üõ†Tecnologias Utilizadas
- **Python**: linguagem de programa√ß√£o escolhida por sua versatilidade e manipula√ß√£o de dados.
- **Pandas**: utilizado para estrutura√ß√£o e manipula√ß√£o dos dados.
- **Requests**: para consumo da API Fake Store.
- **Collections**: especificamente o `defaultdict` para gerenciar e agrupar dados com efici√™ncia.
- **JSON**: Para o arquivo final de sa√≠da.

## üìÑEstrutura do C√≥digo
- **Consumo de dados**: Requisi√ß√µes aos endpoints `/carts` e `/products`.
- **Transforma√ß√£o de dados**: Extra√ß√£o e c√°lculo das informa√ß√µes solicitadas no case.
- **Persist√™ncia**: Salvamento dos dados processados em um arquivo JSON.

## üöÄFuncionalidades
Abaixo est√£o os passos principais e funcionalidades do c√≥digo.

### üìçRequisi√ß√£o dos Dados:
Fiz a requisi√ß√£o √† Fake Store API para buscar informa√ß√µes de carrinhos e produtos.

    url_carrinho = "https://fakestoreapi.com/carts"
    response_carrinho = requests.get(url_carrinho)

    url_produtos = "https://fakestoreapi.com/products"
    response_produtos = requests.get(url_produtos)

Ap√≥s cada requisi√ß√£o, verifico se a resposta foi bem-sucedida `status 200`. Se houver erro, exibo uma mensagem de alerta.

    if response_carrinho.status_code == 200:
    dados_carrinho = response_carrinho.json()
    else:
    print("Erro ao acessar a API de carrinhos")
    
    if response_produtos.status_code == 200:
    dados_produtos = response_produtos.json()
    else:
    print("Erro ao acessar a API de produtos")

### üìçTransforma√ß√£o dos Dados:
Utilizei um `defaultdict` para mapear cada `user_id` e processei cada carrinho para identificar:
- A data mais recente de adi√ß√£o ao carrinho para cada usu√°rio.
- A categoria de produto mais adicionada no carrinho de cada usu√°rio.

Mapeamento do ID do produto para a categoria e dicion√°rio para armazenar o resultado final:

    produto_para_categoria = {produto['id']: produto['category'] for produto in dados_produtos}
    dados_finais = defaultdict(lambda: {'ultima_data': None, 'categorias': defaultdict(int)})

Processando cada carrinho para extrair as informa√ß√µes:

    for carrinho in dados_carrinho:
    user_id = carrinho['userId']
    date_str = carrinho['date'].split('.')[0].rstrip('Z')
    data = datetime.fromisoformat(date_str)

Atualizando a data mais recente de adi√ß√£o ao carrinho:
    
    if dados_finais[user_id]['ultima_data'] is None or data > dados_finais[user_id]['ultima_data']:
        dados_finais[user_id]['ultima_data'] = data

Contando os produtos por categoria:
    
    for produto in carrinho['products']:
        categoria = produto_para_categoria[produto['productId']]
        dados_finais[user_id]['categorias'][categoria] += produto['quantity']

### üìçPrepara√ß√£o do Resultado Final:
- Ap√≥s processar todos os carrinhos, percorro os dados finais de cada usu√°rio para identificar a categoria com o maior n√∫mero de produtos adicionados.
- Crio uma lista chamada `resultado_final`, onde cada entrada cont√©m o `user_id`, a `ultima_data` e a `categoria_mais_produtos` do usu√°rio.

Preparando a sa√≠da final com a categoria mais frequente:

    resultado_final = []
    for user_id, info in dados_finais.items():
    categoria_mais_freq = max(info['categorias'], key=info['categorias'].get)
    resultado_final.append({
        "user_id": user_id,
        "ultima_data": info['ultima_data'].isoformat(),
        "categoria_mais_produtos": categoria_mais_freq

### üìçGera√ß√£o do Arquivo JSON:
Com os dados processados, criei um `DataFrame` e o salvei em JSON, facilitando o uso em outras ferramentas.
O arquivo cont√©m:
-   `user_id`: identificador √∫nico do usu√°rio.
-   `ultima_data`: √∫ltima data de adi√ß√£o de produto ao carrinho.
-   `categoria_mais_produtos`: categoria com maior quantidade de produtos adicionados.

Criando o dataFrame com o resultado final:
        
    df = pd.dataFrame(resultado_final)

Salvando no formato JSON:

    df.to_json("Case Data Engineer I - Pedro Augusto.json", orient="records")

## üíæSa√≠da do arquivo JSON
A sa√≠da gerada ser√° um arquivo JSON com o seguinte formato:

    [{"user_id":1,"ultima_data":"2020-03-02T00:00:00","categoria_mais_produtos":"men's clothing"},{"user_id":2,"ultima_data":"2020-03-01T00:00:00","categoria_mais_produtos":"men's clothing"},{"user_id":3,"ultima_data":"2020-03-01T00:00:00","categoria_mais_produtos":"men's clothing"},{"user_id":4,"ultima_data":"2020-03-01T00:00:00","categoria_mais_produtos":"electronics"},{"user_id":8,"ultima_data":"2020-03-01T00:00:00","categoria_mais_produtos":"women's clothing"}]

O arquivo JSON cont√©m informa√ß√µes agregadas de cada usu√°rio, resumindo a √∫ltima data de adi√ß√£o ao carrinho e a categoria mais popular.

## ‚úÖAn√°lise de Efici√™ncia
- **Efici√™ncia**: O uso de `defaultdict` reduz a complexidade ao contar produtos por categoria, tornando o processamento de dados mais eficiente.
- **Escalabilidade**: A abordagem atual √© eficaz para o volume de dados da API, mas, para grandes volumes seria bom considerar o uso de frameworks de processamento em lote.
- **Tratamento de Erros**: Mensagens s√£o exibidas para sinalizar qualquer problema de conex√£o com a API.
- **Documenta√ß√£o**: Cada se√ß√£o do c√≥digo inclui coment√°rios que explicam o prop√≥sito de cada bloco, visando facilitar a manuten√ß√£o e a extens√£o da solu√ß√£o.

## üòäAgradecimentos
Agrade√ßo √† equipe Enjoei/Elo7 pela oportunidade de realizar este case, estou entusiasmado com a possibilidade de contribuir para o time de engenharia de dados e explorar solu√ß√µes inovadoras na √°rea de dados. Agrade√ßo mais uma vez pela oportunidade e fico √† disposi√ß√£o para qualquer etapa adicional do processo.

## Licen√ßa
Este projeto est√° sob a **Licen√ßa MIT**.
